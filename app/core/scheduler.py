"""
Task scheduler system for managing periodic operations.

This module provides a flexible and robust TaskScheduler class for managing
periodic tasks with configurable intervals, priorities, and concurrency.
"""

import asyncio
import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional
import heapq


class TaskState(str, Enum):
    """Enum representing the possible states of a scheduled task."""

    PENDING = "pending"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    ERROR = "error"


@dataclass
class TaskStatistics:
    """Statistics for a scheduled task."""

    created_at: datetime = field(default_factory=datetime.now)
    last_run_at: Optional[datetime] = None
    last_success_at: Optional[datetime] = None
    last_error_at: Optional[datetime] = None
    next_run_at: Optional[datetime] = None
    total_runs: int = 0
    successful_runs: int = 0
    failed_runs: int = 0
    average_duration_ms: float = 0.0
    total_duration_ms: float = 0.0


@dataclass
class ScheduledTask:
    """A task scheduled for periodic execution."""

    name: str
    task_func: Callable
    interval: float
    priority: int
    state: TaskState = TaskState.PENDING
    last_run_time: float = 0.0
    retry_count: int = 0
    stats: TaskStatistics = field(default_factory=TaskStatistics)
    _task_id: int = field(default=0)

    def __post_init__(self):
        # Calculate next run time based on interval
        self.stats.next_run_at = datetime.now()

    def __lt__(self, other):
        """For priority queue ordering, lower priority numbers go first."""
        # Order first by next run time, then by priority
        my_next_run = self.last_run_time + self.interval
        other_next_run = other.last_run_time + other.interval

        if abs(my_next_run - other_next_run) < 0.001:  # Nearly same time
            return self.priority < other.priority
        return my_next_run < other_next_run


class TaskScheduler:
    """
    Scheduler for managing periodic tasks.

    Features:
    - Concurrent task execution using asyncio or threading
    - Priority-based scheduling
    - Configurable intervals for each task
    - Error handling and retry logic
    - Task status monitoring
    - Graceful shutdown capabilities
    """

    def __init__(
        self,
        max_workers: int = 10,
        use_asyncio: bool = True,
        max_retries: int = 3,
        retry_delay: float = 5.0,
        logger: Optional[logging.Logger] = None,
    ):
        """
        Initialize the TaskScheduler.

        Args:
            max_workers: Maximum number of concurrent tasks
            use_asyncio: Whether to use asyncio or threading for concurrency
            max_retries: Maximum number of retry attempts for failed tasks
            retry_delay: Delay in seconds between retry attempts
            logger: Logger instance for logging events
        """
        self._logger = logger or logging.getLogger(__name__)
        self._use_asyncio = use_asyncio
        self._max_workers = max_workers
        self._max_retries = max_retries
        self._retry_delay = retry_delay

        # Task storage
        self._tasks: Dict[str, ScheduledTask] = {}
        self._task_priority_queue: List[ScheduledTask] = []
        self._task_counter = 0

        # Concurrency controls
        self._running = False
        self._stop_event = threading.Event()
        self._lock = threading.RLock()

        # Thread or asyncio event loop
        self._scheduler_thread: Optional[threading.Thread] = None
        self._thread_pool: Optional[ThreadPoolExecutor] = None
        self._loop: Optional[asyncio.AbstractEventLoop] = None

        self._logger.info(
            f"TaskScheduler initialized with {'asyncio' if use_asyncio else 'threading'} "
            f"and {max_workers} max workers"
        )

    def add_task(
        self,
        task_func: Callable,
        interval: float,
        name: Optional[str] = None,
        priority: int = 100,
    ) -> str:
        """
        Add a task to the scheduler.

        Args:
            task_func: Function or coroutine to execute
            interval: Time interval in seconds between executions
            name: Unique name for the task (autogenerated if not provided)
            priority: Priority value (lower values = higher priority)

        Returns:
            Task name that can be used to reference the task

        Raises:
            ValueError: If a task with this name already exists
        """
        if not name:
            name = f"task_{self._task_counter}"

        with self._lock:
            if name in self._tasks:
                raise ValueError(f"Task with name '{name}' already exists")

            self._task_counter += 1
            task = ScheduledTask(
                name=name,
                task_func=task_func,
                interval=interval,
                priority=priority,
                _task_id=self._task_counter,
            )

            self._tasks[name] = task
            self._update_task_queue()

            self._logger.debug(
                f"Added task '{name}' with interval {interval}s and priority {priority}"
            )
            return name

    def remove_task(self, name: str) -> bool:
        """
        Remove a task from the scheduler.

        Args:
            name: Name of the task to remove

        Returns:
            True if task was removed, False if task not found
        """
        with self._lock:
            if name not in self._tasks:
                self._logger.warning(f"Attempted to remove non-existent task '{name}'")
                return False

            del self._tasks[name]
            self._update_task_queue()

            self._logger.debug(f"Removed task '{name}'")
            return True

    def start(self):
        """
        Start the scheduler.

        Raises:
            RuntimeError: If scheduler is already running
        """
        with self._lock:
            if self._running:
                raise RuntimeError("Scheduler is already running")

            self._running = True
            self._stop_event.clear()

            if self._use_asyncio:
                self._start_asyncio_scheduler()
            else:
                self._start_threaded_scheduler()

            self._logger.info("TaskScheduler started")

    def stop(self, timeout: float = 10.0) -> bool:
        """
        Stop the scheduler gracefully.

        Args:
            timeout: Maximum time to wait for scheduler to stop

        Returns:
            True if stopped successfully, False if timed out
        """
        if not self._running:
            self._logger.warning("Attempted to stop scheduler that is not running")
            return True

        self._logger.info("Stopping TaskScheduler...")
        self._stop_event.set()
        self._running = False

        if self._scheduler_thread and self._scheduler_thread.is_alive():
            self._scheduler_thread.join(timeout)
            success = not self._scheduler_thread.is_alive()
        else:
            success = True

        # Clean up resources
        if self._thread_pool:
            self._thread_pool.shutdown(wait=False)
            self._thread_pool = None

        self._logger.info(
            f"TaskScheduler {'stopped successfully' if success else 'stop timed out'}"
        )
        return success

    def pause_task(self, name: str) -> bool:
        """
        Pause a task temporarily.

        Args:
            name: Name of the task to pause

        Returns:
            True if task was paused, False if task not found
        """
        with self._lock:
            if name not in self._tasks:
                self._logger.warning(f"Attempted to pause non-existent task '{name}'")
                return False

            task = self._tasks[name]
            if task.state == TaskState.PAUSED:
                return True

            task.state = TaskState.PAUSED
            self._update_task_queue()

            self._logger.debug(f"Paused task '{name}'")
            return True

    def resume_task(self, name: str) -> bool:
        """
        Resume a paused task.

        Args:
            name: Name of the task to resume

        Returns:
            True if task was resumed, False if task not found or not paused
        """
        with self._lock:
            if name not in self._tasks:
                self._logger.warning(f"Attempted to resume non-existent task '{name}'")
                return False

            task = self._tasks[name]
            if task.state != TaskState.PAUSED:
                return False

            task.state = TaskState.PENDING
            task.last_run_time = 0  # Schedule to run soon
            self._update_task_queue()

            self._logger.debug(f"Resumed task '{name}'")
            return True

    def get_task_status(self, name: str) -> Optional[Dict[str, Any]]:
        """
        Get the current status and statistics for a task.

        Args:
            name: Name of the task

        Returns:
            Dictionary with task status and statistics, or None if task not found
        """
        with self._lock:
            if name not in self._tasks:
                return None

            task = self._tasks[name]

            return {
                "name": task.name,
                "state": task.state.value,
                "priority": task.priority,
                "interval": task.interval,
                "last_run_time": task.last_run_time,
                "retry_count": task.retry_count,
                "stats": {
                    "created_at": task.stats.created_at.isoformat(),
                    "last_run_at": (
                        task.stats.last_run_at.isoformat() if task.stats.last_run_at else None
                    ),
                    "last_success_at": (
                        task.stats.last_success_at.isoformat()
                        if task.stats.last_success_at
                        else None
                    ),
                    "last_error_at": (
                        task.stats.last_error_at.isoformat() if task.stats.last_error_at else None
                    ),
                    "next_run_at": (
                        task.stats.next_run_at.isoformat() if task.stats.next_run_at else None
                    ),
                    "total_runs": task.stats.total_runs,
                    "successful_runs": task.stats.successful_runs,
                    "failed_runs": task.stats.failed_runs,
                    "average_duration_ms": task.stats.average_duration_ms,
                },
            }

    def get_all_tasks_status(self) -> Dict[str, Dict[str, Any]]:
        """
        Get status and statistics for all tasks.

        Returns:
            Dictionary mapping task names to status dictionaries
        """
        with self._lock:
            return {name: self.get_task_status(name) for name in self._tasks}

    def _update_task_queue(self):
        """Update the priority queue for task scheduling."""
        with self._lock:
            # Rebuild the priority queue
            self._task_priority_queue = [
                task
                for task in self._tasks.values()
                if task.state not in (TaskState.PAUSED, TaskState.COMPLETED)
            ]
            heapq.heapify(self._task_priority_queue)

    def _start_threaded_scheduler(self):
        """Start the scheduler using threads for concurrency."""
        self._thread_pool = ThreadPoolExecutor(max_workers=self._max_workers)
        self._scheduler_thread = threading.Thread(
            target=self._run_scheduler_loop,
            name="TaskScheduler",
            daemon=True,
        )
        self._scheduler_thread.start()

    def _start_asyncio_scheduler(self):
        """Start the scheduler using asyncio for concurrency."""
        if not self._loop:
            self._loop = asyncio.new_event_loop()

        self._thread_pool = ThreadPoolExecutor(max_workers=self._max_workers)
        self._scheduler_thread = threading.Thread(
            target=self._run_asyncio_loop,
            name="TaskSchedulerAsyncio",
            daemon=True,
        )
        self._scheduler_thread.start()

    def _run_scheduler_loop(self):
        """Main scheduler loop for threaded execution."""
        while not self._stop_event.is_set():
            self._process_due_tasks()
            time.sleep(0.1)  # Small sleep to prevent CPU hogging

    def _run_asyncio_loop(self):
        """Run the asyncio event loop for the scheduler."""
        asyncio.set_event_loop(self._loop)
        self._loop.run_until_complete(self._asyncio_scheduler_loop())

    async def _asyncio_scheduler_loop(self):
        """Main scheduler loop for asyncio execution."""
        while not self._stop_event.is_set():
            self._process_due_tasks()
            await asyncio.sleep(0.1)  # Small sleep to prevent CPU hogging

    def _process_due_tasks(self):
        """Process tasks that are due to run."""
        current_time = time.time()

        with self._lock:
            # Process tasks that are due
            tasks_to_run = []

            # Check if any tasks are due
            while self._task_priority_queue:
                # Peek at the next task without removing it
                next_task = self._task_priority_queue[0]

                # If the task is due to run
                if next_task.last_run_time + next_task.interval <= current_time:
                    # Pop the task and add it to the list to run
                    task = heapq.heappop(self._task_priority_queue)
                    tasks_to_run.append(task)
                else:
                    # No more due tasks
                    break

        # Execute the tasks outside the lock
        for task in tasks_to_run:
            self._execute_task(task)

            # Update the task queue after execution
            with self._lock:
                if task.name in self._tasks:  # The task might have been removed
                    # Update and re-add to queue if not paused or completed
                    if task.state not in (TaskState.PAUSED, TaskState.COMPLETED):
                        heapq.heappush(self._task_priority_queue, task)

    def _execute_task(self, task: ScheduledTask):
        """
        Execute a task and handle success/failure.

        Args:
            task: The task to execute
        """
        task.state = TaskState.RUNNING
        task.stats.total_runs += 1
        task.stats.last_run_at = datetime.now()
        start_time = time.time()

        try:
            self._logger.debug(f"Executing task '{task.name}'")

            if self._use_asyncio and asyncio.iscoroutinefunction(task.task_func):
                # Execute coroutine in the asyncio loop
                future = asyncio.run_coroutine_threadsafe(task.task_func(), self._loop)
                # Wait for the result (which may raise an exception) with timeout
                future.result(timeout=task.interval)
            else:
                # Execute in thread pool
                future = self._thread_pool.submit(task.task_func)
                # Wait for the result (which may raise an exception) with timeout
                future.result(timeout=task.interval)

            # Success handling
            self._handle_task_success(task, start_time)

        except Exception as e:
            # Error handling
            self._handle_task_error(task, e, start_time)

    def _handle_task_success(self, task: ScheduledTask, start_time: float):
        """Handle successful task execution."""
        duration_ms = (time.time() - start_time) * 1000

        with self._lock:
            if task.name not in self._tasks:
                return  # Task was removed during execution

            task.last_run_time = time.time()
            task.retry_count = 0
            task.state = TaskState.PENDING

            # Update statistics
            task.stats.successful_runs += 1
            task.stats.last_success_at = datetime.now()
            task.stats.total_duration_ms += duration_ms
            task.stats.average_duration_ms = (
                task.stats.total_duration_ms / task.stats.successful_runs
            )
            task.stats.next_run_at = datetime.fromtimestamp(task.last_run_time + task.interval)

            self._logger.debug(f"Task '{task.name}' completed successfully in {duration_ms:.2f}ms")

    def _handle_task_error(self, task: ScheduledTask, error: Exception, start_time: float):
        """Handle task execution error."""
        with self._lock:
            if task.name not in self._tasks:
                return  # Task was removed during execution

            task.retry_count += 1
            task.stats.failed_runs += 1
            task.stats.last_error_at = datetime.now()

            self._logger.error(
                f"Task '{task.name}' failed: {error}. "
                f"Retry {task.retry_count}/{self._max_retries}"
            )

            if task.retry_count <= self._max_retries:
                # Schedule for retry
                task.state = TaskState.PENDING
                task.last_run_time = time.time() - task.interval + self._retry_delay
                task.stats.next_run_at = datetime.fromtimestamp(task.last_run_time + task.interval)
            else:
                # Max retries exceeded
                task.state = TaskState.ERROR
                self._logger.error(
                    f"Task '{task.name}' failed after {self._max_retries} retries: {error}"
                )
